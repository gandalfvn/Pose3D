# Reading list and research resources on 3D pose estimation and reconstruction 

## Selected papers

* Accurate Single Stage Detector Using Recurrent Rolling Convolution. CVPR'17. Arxiv [1704.05776](https://arxiv.org/abs/1704.05776). Competitive [results](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d) on [KITTI](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d) dataset. Code on [github](https://github.com/xiaohaoChen/rrc_detection).

* Deep MANTA: A Coarse-to-fine Many-Task Network for joint 2D and 3D vehicle analysis from monocular image. CVPR'17. Arxiv [1703.07570v1](https://arxiv.org/abs/1703.07570). Part of a self-driving car [project](http://www.bdva.eu/sites/default/files/%5B30th_Nov%5D-10-Geraud_CEA.pdf) called [Easy Mile](http://easymile.com). Achieved top [results](http://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=6759889c0a252c63765d5e2e69cb8b1433cadb0a) (96.4/90.1/80.79 mAP, as of Nov. 2017) for vehicle detection on [KITTI](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d) dataset.

* Rethinking Reprojection: Closing the Loop for Pose-aware Shape Reconstruction from a Single Image. ICCV'17. Arxiv [1707.04682](https://arxiv.org/abs/1707.04682 "PDF"). [Supplementary Material](http://www.hamedkiani.com/uploads/5/1/8/8/51882963/rr_sup.pdf "PDF").

* MarrNet: 3D Shape Reconstruction via 2.5D Sketches. Arxiv [1711.03129](https://arxiv.org/abs/1711.03129 "PDF").

## Benchmark datasets and baselines

* [KITTI](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d) real-world computer vision benchmark suit. 26.07.2017: added novel benchmarks for 3D object detection including 3D and bird's eye view evaluation.

* CMU's [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) real-time multi-person keypoint detection library for body, face, and hands estimation.

## Simulators

* [CARLA](http://www.carla.org/) is an open-source simulator for autonomous driving research. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions.

* [HoME](https://home-platform.github.io) a Household Multimodal Environment for artificial agents to learn from vision, audio, semantics, physics, and interaction with objects and other agents, all within a realistic context.

## Other references

* [A year in CV](http://www.themtank.org/a-year-in-computer-vision), the MTank.

